# Snakemake workflow for performing several population genomic comparisons of population replicates across two different
# habitat categories and two different time periods. These units however can be changed to any categorical variable with
# two different types.

report: "report/workflow.rst"

include: "rules/common.smk"
include: "rules/other.smk"

import pandas as pd
from snakemake.utils import validate, min_version

# Set minimum snakemake version
min_version("6.2.1")

# load config and sample sheets
configfile: "config.yaml"

samples_df = pd.read_table(config["samples"]).set_index("sample", drop=False)
mus_sample_list = list(samples_df.index[samples_df.time == "mus"])
mod_sample_list = list(samples_df.index[samples_df.time == "mod"])
all_sample_list = mod_sample_list + mus_sample_list
samples_df["timepop"] = samples_df["time"] + "_" + samples_df["population"]
pop_list = list(set(samples_df.timepop[samples_df.time != "neg"]))
pop_list = ["mus_Tvedora"]

wildcard_constraints:
    mus_sample_id= '|'.join([re.escape(x) for x in mus_sample_list]),
    mod_sample_id= '|'.join([re.escape(x) for x in mod_sample_list])

rule all:
    """
    Collect the main outputs of the workflow.
    """
    input:
        expand("results/mapping/mapdamage/{sample_id}_{alg}_sorted/Fragmisincorporation_plot.pdf", sample_id=mus_sample_list, alg=["mem","aln"])

rule download_index_ref:
    """
    Downloads reference genome and indexes with samtools and bwa
    """
    output:
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.amb"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.ann"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.bwt"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.pac"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.sa"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.fai"),
        protected("data/reference/20200120.hicanu.purge.prim.fasta.gz.gzi")
    log:
        "results/logs/prep_reference.log"
    shell:
        """
        mkdir -p data/reference
        cd data/reference

        wget https://darwin.cog.sanger.ac.uk/insects/Polyommatus_icarus/ilPolIcar1/assemblies/working/20200120.hicanu.purge/20200120.hicanu.purge.prim.fasta.gz

        bwa index 20200120.hicanu.purge.prim.fasta.gz
        samtools faidx 20200120.hicanu.purge.prim.fasta.gz
        """

rule fastp_filter_mod:
    """
    Removes adapters, poly-G tails, and low quality bases at the ends of reads.
    Does not merge reads. Discards unpaired reads and reads failing filters.
    """
    output:
        modR1="data/fastq_clean/{mod_sample_id}.R1.clean.gz",
        modR2="data/fastq_clean/{mod_sample_id}.R2.clean.gz",
        modhtml="results/fastp_report/{mod_sample_id}.fastp.html",
        modjson="results/fastp_report/{mod_sample_id}.fastp.json"
    params:
        ngi_id = lambda wildcards: mod_samples_df['ngi_id'][wildcards.mod_sample_id]
    resources:
        runtime = lambda wildcards, attempt: attempt*60
    threads: 4
    shell:
        """
        mkdir -p data/fastq_clean
        mkdir -p results/fastp_report

        fastp -i data/fastq_raw/{params.ngi_id}*_R1_001.fastq.gz \
            -I data/fastq_raw/{params.ngi_id}*_R2_001.fastq.gz \
            -o {output.modR1} -O {output.modR2} -h {output.modhtml} \
            -j {output.modjson} -g -p -w {threads}
        """

rule fastp_filter_mus:
    """
    Removes adapters, poly-G tails, and low quality bases at the end of reads.
    Merges reads. Discards unpaired reads and reads failing filters. Unmerged
    reads are saved to R1 and R2 files.
    """
    output:
        R1="data/fastq_clean/{mus_sample_id}.R1.clean.gz",
        R2="data/fastq_clean/{mus_sample_id}.R2.clean.gz",
        merged="data/fastq_clean/{mus_sample_id}.merge.clean.gz",
        html="results/fastp_report/{mus_sample_id}.fastp.html",
        json="results/fastp_report/{mus_sample_id}.fastp.json"
    params:
        ngi_id = lambda wildcards: mus_samples_df['ngi_id'][wildcards.mus_sample_id]
    resources:
        runtime = lambda wildcards, attempt: attempt*60
    threads: 4
    shell:
        """
        mkdir -p data/fastq_clean
        mkdir -p results/fastp_report

        fastp -i data/fastq_raw/{params.ngi_id}*_R1_001.fastq.gz \
            -I data/fastq_raw/{params.ngi_id}*_R2_001.fastq.gz \
            -m --merged_out={output.merged} \
            -o {output.R1} -O {output.R2} -h {output.html} -j {output.json} \
            -g -p -w {threads}
        """

rule bwa_map_mod_mem:
    """
    Maps reads to reference using bwa-mem
    """
    input:
        reads=expand(["data/fastq_clean/{mod_sample_id}.R1.clean.gz",
            "data/fastq_clean/{mod_sample_id}.R2.clean.gz"], mod_sample_id=mod_sample_list),
        ref="data/reference/20200120.hicanu.purge.prim.fasta.gz",
        refidx="data/reference/20200120.hicanu.purge.prim.fasta.gz.bwt"
    output:
        "data/bams/{mod_sample_id}.mem.sorted.bam"
    resources:
        runtime = 1440
    threads: 20
    shell:
        """
        mkdir -p data/bams
        bwa mem -t {threads} {input.ref} data/fastq_clean/{wildcards.mod_sample_id}.R1.clean.gz \
            data/fastq_clean/{wildcards.mod_sample_id}.R2.clean.gz | samtools sort \
            -o {output[0]}
        """

rule bwa_map_mus_aln:
    """
    Maps reads to reference using bwa-mem
    """
    input:
        reads="data/fastq_clean/{mus_sample_id}.merge.clean.gz",
        ref="data/reference/20200120.hicanu.purge.prim.fasta.gz",
        refidx="data/reference/20200120.hicanu.purge.prim.fasta.gz.bwt"
    output:
        "data/bams/{mus_sample_id}.aln.sorted.bam"
    resources:
        runtime = 2880,
        tmpdir = 'scratch/$SLURM_JOB_ID'
    threads: 20
    shell:
        """
        mkdir -p data/bams

        bwa aln -t {threads} -l 16500 -n 0.01 -o 2 \
            -f {resources.tmpdir}/{wildcards.mus_sample_id}.aln.sai {input.ref} {input.reads}

        bwa samse -f temp/{wildcards.mus_sample_id}.aln.sam {input.ref} \
            {resources.tmpdir}/{wildcards.mus_sample_id}.aln.sai {input.reads}

        samtools view -b {resources.tmpdir}/{wildcards.mus_sample_id}.aln.sam | samtools \
            sort -o {output[0]}
        """

rule bwa_map_mus_mem:
    """
    Maps reads to reference using bwa-mem
    """
    input:
        reads=expand("data/fastq_clean/{mus_sample_id}.merge.clean.gz", mus_sample_id=mus_sample_list),
        ref="data/reference/20200120.hicanu.purge.prim.fasta.gz",
        refidx="data/reference/20200120.hicanu.purge.prim.fasta.gz.bwt"
    output:
        "data/bams/{mus_sample_id}.mem.sorted.bam"
    resources:
        runtime = 1440
    threads: 20
    shell:
        """
        bwa mem -t {threads} {input.ref} data/fastq_clean/{wildcards.mus_sample_id}.merge.clean.gz | samtools sort \
            -o {output[0]}
        """

rule qualimap_prededup:
    """
    Runs qualimap before duplicate removal
    """
    input:
        "data/bams/{sample_id}.mem.sorted.bam",
        "data/bams/{sample_id}.aln.sorted.bam"
    output:
        "results/mapping/qualimap/{sample_id}_mem_sorted/{sample_id}.mem.sorted.qualimap.pdf",
        "results/mapping/qualimap/{sample_id}_aln_sorted/{sample_id}.aln.sorted.qualimap.pdf"
    resources:
        runtime = 480
    shell:
        """
        qualimap bamqc -bam data/bams/{wildcards.sample_id}.mem.sorted.bam \
            -outdir results/mapping/qualimap/{wildcards.sample_id}_mem_sorted \
            -outfile {wildcards.sample_id}.mem.sorted.qualimap.pdf
        
        qualimap bamqc -bam data/bams/{wildcards.sample_id}.aln.sorted.bam \
            -outdir results/mapping/qualimap/{wildcards.sample_id}_aln_sorted \
            -outfile {wildcards.sample_id}.aln.sorted.qualimap.pdf
        """

rule mapdamage_prededup:
    """
    Runs mapdamage check on bam files before duplicate removal, both aln and mem
    """
    input:
        bam="data/bams/{sample_id}.{alg}.sorted.bam",
        ref="data/reference/20200120.hicanu.purge.prim.fasta.gz"
    output:
        "results/mapping/mapdamage/{sample_id}_{alg}_sorted/Fragmisincorporation_plot.pdf"
    resources:
        runtime = 1440
    shell:
        """
        mapDamage -i {input.bam} -r {input.ref} -d results/mapping/mapdamage/{wildcards.sample_id}_{wildcards.alg}_sorted
        """

rule picard_dedup:
    """
    Removes duplicate reads from bam files
    """
    input:
        "data/bams/{sample_id}.mem.sorted.bam"
    output:
        bam=protected("data/bams/{sample_id}.mem.sorted.dedup.bam"),
        metrics=protected("data/bams/{sample_id}.mem.sorted.dedup.metrics.txt")
    resources:
        runtime = 240
    shell:
        """
        picard MarkDuplicates REMOVE_DUPLICATES=true I={input[0]} \
            O={output.bam} M={output.metrics}
        """

rule qualimap_postdedup:
    """
    Runs qualimap after duplicate removal
    """
    input:
        "data/bams/{sample_id}.mem.sorted.dedup.bam"
    output:
        "results/mapping/qualimap/{sample_id}_mem_sorted_dedup/{sample_id}.mem.sorted.dedup.qualimap.pdf"
    resources:
        runtime = 240
    shell:
        """
        qualimap bamqc -bam {input} -outdir results/mapping/qualimap/{wildcards.sample_id}_mem_sorted_dedup \
            -outfile {wildcards.sample_id}.mem.sorted.dedup.qualimap.pdf
        """

rule samtools_index_bam:
    """
    Indexes bam file after sorting and duplicate removal
    """
    input:
        "data/bams/{sample_id}.mem.sorted.dedup.bam"
    output:
        protected("data/bams/{sample_id}.mem.sorted.dedup.bam.bai")
    resources:
        runtime = 10
    shell:
        """
        samtools index data/bams/{wildcards.sample_id}.mem.sorted.dedup.bam
        """

def population2bams(wildcards):
    return expand(
        "data/bams/{sample_id}.mem.sorted.dedup.bam", sample_id =
            samples_df.index[samples_df.timepop == wildcards.population]
    )

def population2bais(wildcards):
    return expand(
        "data/bams/{sample_id}.mem.sorted.dedup.bam.bai", sample_id =
            samples_df.index[samples_df.timepop == wildcards.population]
    )

rule bamlist_perpop:
    """
    Make a bamlist from all samples in each population
    """
    input:
        bams = population2bams
    output:
        "data/bams/{population}.bamlist"
    resources:
        runtime = 5
    shell:
        """
        (readlink -f {input.bams} | perl -pe 'chomp if eof') > {output}
        """

rule angsd_perpop_saf:
    """
    Make a saf file from all samples in each population
    """
    input:
        bamlist="data/bams/{population}.bamlist",
        bams=population2bams,
        bais=population2bais,
        ref="data/reference/20200120.hicanu.purge.prim.fasta.gz"
    output:
        "data/saf/{population}.saf.gz",
        "data/saf/{population}.saf.idx"
    params:
        outpre="data/saf/{population}",
        missdata=0.8
    resources:
        runtime = 14400
    threads: 4
    shell:
        """
        mkdir -p data/saf

        TOTIND=$(wc -l < {input.bamlist})

        MININD=$(printf "%.0f\n" $(bc <<< "($TOTIND * {params.missdata}) + 0.5"))

        angsd -GL 1 -nThreads {threads} -dosaf 1 -doMajorMinor 1 \
            -c 50 -uniqueOnly 1 -minQ 20 -baq 1 -doMaf 1 \
            -remove_bads 1 -minInd $MININD -bam {input.bamlist} -out {params.outpre} \
            -ref {input.ref} -anc {input.ref}
        """

rule angsd_perpop_sfs:
    """
    Make an 1D folded SFS for all samples in each population
    """
    input:
        saf="data/saf/{population}.saf.idx"
    output:
        "data/sfs/{population}.fold.sfs"
    resources:
        runtime = 240
    threads: 20
    shell:
        """
        mkdir -p data/sfs

        ~/angsd/misc/realSFS {input.saf} -P {threads} -fold 1 > {output}
        """
